# -*- coding: utf-8 -*-
"""Diabetic_Retinopathy_latest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11mXiZnIUXvyEYGd0XgTsfiWuZX9ghOr7
"""

# buffer size
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_theme(style = 'darkgrid')
from IPython.display import Image, display
import matplotlib.cm as cm
import time
import tensorflow as tf 
! pip install tensorflow-addons
from tensorflow.image import ResizeMethod
import tensorflow_addons as tfa
from tensorflow import keras
import sklearn
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input
from keras.applications.inception_v3 import InceptionV3
from keras.applications.resnet_v2 import ResNet50V2
from keras.applications.efficientnet_v2 import EfficientNetV2B3


# import os
# import cv2
# import numpy as np

from google.colab import drive
drive.mount('/content/drive')

# # creating Clahe processed dataset for both train and test in order to save the computational time
# # during training and testing.

# def clahe_processed_dataset_gen(input_dir, output_dir):
#   # Create the output directory if it does not exist
#   if not os.path.exists(output_dir):
#     os.makedirs(output_dir)

#   # Loop through the images in the input directory
#   for filename in os.listdir(input_dir):
#     # Read the image
#     img = cv2.imread(os.path.join(input_dir, filename))
#     img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)
    
#     # Apply CLAHE to the image
#     clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
#     img_lab[...,0] = clahe.apply(img_lab[...,0])
#     img_clahe = cv2.cvtColor(img_lab, cv2.COLOR_Lab2RGB)
    
#     # Save the processed image
#     cv2.imwrite(os.path.join(output_dir, filename), img_clahe)

# # Set the input and output directories for test dataset
# input_dir = '/content/drive/MyDrive/IDRID_dataset/images/test'
# output_dir = '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/test'

# clahe_processed_dataset_gen(input_dir, output_dir)

# # Set the input and output directories for test dataset
# input_dir = '/content/drive/MyDrive/IDRID_dataset/images/train'
# output_dir = '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train'

# clahe_processed_dataset_gen(input_dir, output_dir)

img_plt = plt.imread('/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/test/IDRiD_025.jpg')
plt.imshow(img_plt)

# importing data csv file

data = pd.read_csv('/content/drive/MyDrive/IDRID_dataset/labels/train.csv')
data.drop(data.iloc[:,3:], axis = 1, inplace = True)

total_data_amount = len(data)

# Creating Train and Valid dataset 90:10
data = data.sample(frac=1).reset_index(drop=True)
train_data = data.loc[:int(0.9 * total_data_amount)]
val_data = data.loc[int(0.9 * total_data_amount) + 1 : ]

print(total_data_amount)

# Train data
print(train_data.info())
print(train_data.head())
sns.countplot(x = 'Retinopathy grade', hue = 'Risk of macular edema ', data = train_data)

# Validation data
print(val_data.info()) # No null fields
print(val_data.head())
sns.countplot(x = 'Retinopathy grade', hue = 'Risk of macular edema ', data = val_data)

# Preprocessing of train and validation data

def preprocess_data(train_val_data):
  # Converting labels to NRDR and RDR. NRDR = 0 and RDR = 1
  train_val_data['Retinopathy grade'].replace([0,1,2,3,4],[0,0,1,1,1], inplace = True)

  # Converting Risk of macular edema having values 1 and 2 to 1 since they are only present in the retinopathy grade 1
  train_val_data['Risk of macular edema '].replace([1,2],1, inplace = True)

  return train_val_data

train_data = preprocess_data(train_data)
val_data = preprocess_data(val_data)

print(train_data.head())

# Correlation between Retinopathy grade and Risk of macular edema
corr_retino_edema = train_data.corr()

# Plotting correaltion
fig, axes = plt.subplots(1,2, figsize = (15,5))
plt.tight_layout()
sns.heatmap(ax = axes[0], data = corr_retino_edema, annot = True)
sns.countplot(ax = axes[1], x = 'Retinopathy grade', hue = 'Risk of macular edema ', data = train_data)

train_data['Retinopathy grade'].value_counts()

# Test Data

test_data = pd.read_csv('/content/drive/MyDrive/IDRID_dataset/labels/test.csv')
test_data.drop(test_data.iloc[:,3:], axis = 1, inplace = True)
print(test_data.info()) # No null fields
print(test_data.head())
sns.countplot(x = 'Retinopathy grade', hue = 'Risk of macular edema ', data = test_data)

# Preprocessing of test data csv file

# Converting labels to NRDR and RDR. NRDR = 0 and RDR = 1
test_data['Retinopathy grade'] = test_data['Retinopathy grade'].replace([0,1,2,3,4],[0,0,1,1,1])

# Correlation between Retinopathy grade and Risk of macular edema
corr_retino_edema = test_data.corr()

# Converting Risk of macular edema having values 1 and 2 to 1 since they are only present in the retinopathy grade 1
test_data['Risk of macular edema '] = test_data['Risk of macular edema '].replace([1,2],1)

# Plotting correaltion
fig, axes = plt.subplots(1,2, figsize = (15,5))
plt.tight_layout()
sns.heatmap(ax = axes[0], data = corr_retino_edema, annot = True)
sns.countplot(ax = axes[1], x = 'Retinopathy grade', hue = 'Risk of macular edema ', data = test_data)

# Processed test data

print(test_data.head())
print(test_data['Retinopathy grade'].value_counts())
print(test_data['Risk of macular edema '].value_counts())
sns.countplot(x = 'Retinopathy grade', hue = 'Risk of macular edema ', data = test_data)

# Creating Training and Validation Split
# Need to check whether the resizing before applying histogram has any factor 

AUTOTUNE = tf.data.experimental.AUTOTUNE
BATCH_SIZE = 64

# Creating pos and neg train dataset for later balancing
pos_train_data = train_data[train_data['Retinopathy grade'] == 1]
neg_train_data = train_data[train_data['Retinopathy grade'] == 0]

images_directory = '/content/drive/MyDrive/IDRID_dataset/images/'
images_directory_clahe = '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/'

pos_images_paths = 'train/' + pos_train_data['Image name'].values + '.jpg'
neg_images_paths = 'train/' + neg_train_data['Image name'].values + '.jpg'
pos_labels = pos_train_data['Retinopathy grade'].values
neg_labels = neg_train_data['Retinopathy grade'].values

val_images_path = 'train/' + val_data['Image name'].values + '.jpg'
val_labels = val_data['Retinopathy grade'].values

test_images_path = 'test/' + test_data['Image name'].values + '.jpg'
test_labels = test_data['Retinopathy grade'].values


# we have option of passing both the original dataset or clahe processed dataset
def parse_function(filename, label):
    image_string = tf.io.read_file( images_directory_clahe + filename)

    #Don't use tf.image.decode_image, or the output shape will be undefined -- uint8
    image = tf.io.decode_jpeg(image_string, channels=3)

    # Scaling value between 1 and 0
    # image = tf.image.convert_image_dtype(image, tf.float32)

    # according to model used
    image = tf.cast(image, tf.float32)
    # image = tf.keras.applications.inception_v3.preprocess_input(image)
    image = tf.keras.applications.resnet_v2.preprocess_input(image)
   
    image = tf.image.crop_to_bounding_box(image, 0, 200, 2848, 3550)

    image = tf.image.resize_with_pad(
                image,
                256,
                256,
                method=ResizeMethod.BILINEAR,
                antialias=False
                )

    return image, label

def augment(images_labels, seed):
  images, labels= images_labels
  # Make a new seed.
  new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]
  images = tf.image.stateless_random_flip_left_right(images, seed =new_seed)
  k = np.random.uniform(low=1.0, high=20.0)
  images = tfa.image.rotate(images, tf.constant(np.pi / k))
  images = tf.image.stateless_random_flip_up_down(images, seed = new_seed)
  k = np.random.uniform(low=1.0, high=20.0)
  images = tfa.image.rotate(images, 20)
  # images = tf.image.stateless_random_contrast(images , 0.2, 0.5, seed = new_seed)
  # images = tf.image.stateless_random_brightness(images, 0.5, seed = new_seed)
  # images = tf.image.stateless_random_saturation(images, lower=0.1, upper=0.9, seed= new_seed)
  return images, labels   

def make_ds(images_paths, labels):
  ds = tf.data.Dataset.from_tensor_slices((images_paths, labels))
  ds = ds.shuffle(len(images_paths))
  ds = ds.map(parse_function, num_parallel_calls= AUTOTUNE)
  return ds

pos_ds = make_ds(pos_images_paths, pos_labels)
neg_ds = make_ds(neg_images_paths, neg_labels)
val_ds = make_ds(val_images_path, val_labels).batch(BATCH_SIZE)
test_ds = make_ds(test_images_path, test_labels).batch(103)

# Oversampling neg_ds to pos_ds
sample_neg_ds = neg_ds.take(len(pos_ds) - len(neg_ds))
neg_ds = neg_ds.concatenate(sample_neg_ds)


# Balancing
train_dataset = tf.data.Dataset.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])
train_dataset = train_dataset.shuffle(600)#----------------------------------------------------------------------

counter = tf.data.experimental.Counter()
train_ds = tf.data.Dataset.zip((train_dataset, (counter, counter)))
train_ds = train_ds.map(augment, num_parallel_calls = AUTOTUNE)
train_ds = train_ds.batch(BATCH_SIZE)
train_ds = train_ds.prefetch(AUTOTUNE)

# For testing with unsampled data
unsampled_train_dataset = make_ds('train/' + train_data['Image name'].values + '.jpg', train_data['Retinopathy grade'].values)
unsampled_train_ds = tf.data.Dataset.zip((unsampled_train_dataset, (counter, counter)))


unsampled_train_ds = unsampled_train_ds.map(augment, num_parallel_calls = AUTOTUNE)
# unsampled_train_ds = unsampled_train_ds.batch(BATCH_SIZE)
# unsampled_train_ds = unsampled_train_ds.prefetch(AUTOTUNE)

img_plt = plt.imread('/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train/IDRiD_001.jpg')
plt.imshow(img_plt)

for i, j in unsampled_train_ds.take(1):
  i = i * 255
  i = tf.cast(i, tf.uint8)
  print(plt.imshow(i))
  # plt.imshow(i.numpy().astype(np.uint8))
  print(j)

# creating training and test routine

optimizer = keras.optimizers.Adam(learning_rate = 0.001)
loss_fn = keras.losses.BinaryCrossentropy()
loss_metric = keras.metrics.BinaryCrossentropy()
acc_metric = keras.metrics.BinaryAccuracy(name = 'accuracy')
recall_metric = keras.metrics.Recall(name = 'recall')
precision_metric = keras.metrics.Precision(name = 'precision')
f1_metric = tfa.metrics.F1Score(num_classes= 1, average='macro', threshold=0.5)

class Training_routine:
  
  def __init__(self, model_name, epochs, train_dataset, val_dataset):
    self.model_name = model_name
    self.epochs = epochs
    self.train_dataset = train_dataset
    self.val_dataset = val_dataset
  
  @tf.function
  def train_step(self, x, y):
      with tf.GradientTape() as tape:
          logits = self.model_name(x, training=True)
          loss_value = loss_fn(y, logits)
      grads = tape.gradient(loss_value, self.model_name.trainable_weights)
      optimizer.apply_gradients(zip(grads, self.model_name.trainable_weights))
      acc_metric.update_state(y, logits)
      loss_metric.update_state(y, logits)
      recall_metric.update_state(y, logits)
      precision_metric.update_state(y, logits)
      
      return loss_value
  
  @tf.function
  def test_step(self, x, y):
      val_logits = self.model_name(x, training=False)
      acc_metric.update_state(y, val_logits)
      loss_metric.update_state(y, val_logits)
      recall_metric.update_state(y, val_logits)
      precision_metric.update_state(y, val_logits)

  def training(self):
    
    patience = 3
    wait = 0
    best = 0

    for epoch in range(self.epochs):
        start_time = time.time()

        # Iterate over the batches of the dataset.
        for step, (x_batch_train, y_batch_train) in enumerate(self.train_dataset):
            loss_value = self.train_step(x_batch_train, y_batch_train)

        # Display metrics at the end of each epoch.
        train_acc = acc_metric.result()
        train_recall = recall_metric.result()
        train_precision = precision_metric.result()
        train_loss = loss_metric.result()
       
        # Reset training metrics at the end of each epoch
        acc_metric.reset_states()
        recall_metric.reset_states()
        precision_metric.reset_states()
        loss_metric.reset_states()
        

        # Run a validation loop at the end of each epoch.
        for x_batch_val, y_batch_val in self.val_dataset:
            self.test_step(x_batch_val, y_batch_val)

        val_acc = acc_metric.result()
        val_recall = recall_metric.result()
        val_precision = precision_metric.result()
        val_loss = loss_metric.result()
       

        acc_metric.reset_states()
        recall_metric.reset_states()
        precision_metric.reset_states()
        loss_metric.reset_states()

        print(f"\nStart of epoch: {epoch} - Train - loss: {train_loss:.2f}, acc: {train_acc:.2f}, recall: {train_recall:.2f}, precision: {train_precision:.2f}, Val - loss: {val_loss:.2f}, acc: {val_acc:.2f}, recall: {val_recall:.2f}, precision: {val_precision:.2f}, Time: {time.time() - start_time:.2f}" )

        # The early stopping strategy: stop the training if `val_loss` does not
        # decrease over a certain number of epochs.
        wait += 1
        if val_loss > best:
          best = val_loss
          wait = 0
        if wait >= patience:
          break

class Testing_routine:

  def __init__(self, model_name, test_dataset):
    self.model_name = model_name
    self.test_dataset = test_dataset

  @tf.function
  def test_step_2(self, x, y):
      test_logits = self.model_name(x, training=False)
      acc_metric.update_state(y, test_logits)
      loss_metric.update_state(y, test_logits)
      recall_metric.update_state(y, test_logits)
      precision_metric.update_state(y, test_logits)
   

  def testing(self):
      start_time = time.time()
      # Iterate over the batches of the dataset.
      for step, (x_batch_test, y_batch_test) in enumerate(self.test_dataset):
        loss_value = self.test_step_2(x_batch_test, y_batch_test)
      # Display metrics at the end of each epoch.
        test_acc = acc_metric.result()
        test_recall = recall_metric.result()
        test_precision = precision_metric.result()
        test_loss = loss_metric.result()
        
      # Reset testing metrics at the end of each epoch
        acc_metric.reset_states()
        recall_metric.reset_states()
        precision_metric.reset_states()
        loss_metric.reset_states()
      
        print(f"Test - loss: {test_loss:.2f}, acc: {test_acc:.2f}, recall: {test_recall:.2f}, precision: {test_precision:.2f}, Time: {time.time() - start_time:.2f}" )

# Creating a baseline model for comparison purpose :- CNN
from keras import layers, regularizers 


def baseline_CNN_model():
  inputs = keras.Input(shape=(256,256,3))
  x = layers.Conv2D(16, 3, padding='same', activation='relu')(inputs)
  x = layers.MaxPooling2D()(x)
  x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)
  x = layers.MaxPooling2D()(x)
  x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)
  x = layers.MaxPooling2D()(x)
  x = layers.Dropout(0.2)(x)
  x = layers.Flatten()(x)
  x = layers.Dense(128, activation='relu')(x)
  outputs = layers.Dense(1, activation = 'sigmoid')(x)
  baseline_model = keras.Model(inputs, outputs)
  return baseline_model

baseline_model = baseline_CNN_model()

print(baseline_model.summary())

# oversampled data
# Need to apply checkpoints

baseline_model_train = Training_routine(baseline_model, 100, train_ds, val_ds)
baseline_model_test = Testing_routine(baseline_model, test_ds)

baseline_model_train.training()
baseline_model_test.testing()

# metric = [
#     keras.metrics.BinaryAccuracy(name = 'accuracy'),
#     keras.metrics.Recall(name = 'recall'),
#     keras.metrics.Precision(name = 'precision'),
#     tfa.metrics.F1Score(num_classes= 1, average='macro', threshold=0.5),
    
# ]

# baseline_model.compile(
#     loss = keras.losses.BinaryCrossentropy(),
#     optimizer = keras.optimizers.Adam(learning_rate = 0.001),
#     metrics = metric 
# )

# baseline_model.fit(train_ds, epochs = 5, verbose = 2, validation_data=val_ds)
# baseline_model.evaluate(test_ds,verbose = 2)

# Unsampled data
# baseline_model_train = Training_routine(baseline_model, 2, unsampled_train_ds, val_ds)
# baseline_model_test = Testing_routine(baseline_model, test_ds)

# baseline_model_train.training()
# baseline_model_test.testing()

# EfficientNet
input_tensor = Input(shape=(256, 256, 3))

# create the base pre-trained model
base_model = EfficientNetV2B3(input_tensor=input_tensor, weights='imagenet', include_top=False, include_preprocessing=True)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(512, activation='relu')(x)
x = Dropout(0.37)(x)
# and a logistic layer -- let's say we have 2 classes
predictions = Dense(1, activation='sigmoid')(x)

# this is the model we will train
efficient_model = Model(inputs=base_model.input, outputs=predictions)

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional EfficientNet layers
for layer in base_model.layers:
    layer.trainable = False

efficient_model.summary()

# compile the model (should be done *after* setting layers to non-trainable)
efficient_model_train = Training_routine(efficient_model, 5, train_ds, val_ds)
efficient_model_train.training()

# Fine tuning EfficientNet

# at this point, the top layers are well trained and we can start fine-tuning
# convolutional layers from efficient V3. We will freeze the bottom N layers
# and train the remaining top layers.

# let's visualize layer names and layer indices to see how many layers
# we should freeze:
# for i, layer in enumerate(base_model.layers):
#    print(i, layer.name)

# we chose to train the top 2 efficient blocks, i.e. we will freeze
# the first 249 layers and unfreeze the rest:
for layer in efficient_model.layers[:360]:
   layer.trainable = False
for layer in efficient_model.layers[360:]:
   layer.trainable = True

# we need to recompile the model for these modifications to take effect
efficient_model_train = Training_routine(efficient_model, 10, train_ds, val_ds)
efficient_model_test = Testing_routine(efficient_model, test_ds)

efficient_model_train.training()
efficient_model_test.testing()

# Transfer Learning --- InceptionV3




input_tensor = Input(shape=(256, 256, 3))

# create the base pre-trained model
base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(512, activation='relu')(x)
x = Dropout(0.37)(x)
# and a logistic layer -- let's say we have 2 classes
predictions = Dense(1, activation='sigmoid')(x)

# this is the model we will train
inception_model = Model(inputs=base_model.input, outputs=predictions)

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional InceptionV3 layers
for layer in base_model.layers:
    layer.trainable = False

inception_model.summary()

# compile the model (should be done *after* setting layers to non-trainable)
inception_model_train = Training_routine(inception_model, 5, train_ds, val_ds)
inception_model_train.training()

# Fine tuning inceptionV3

# at this point, the top layers are well trained and we can start fine-tuning
# convolutional layers from inception V3. We will freeze the bottom N layers
# and train the remaining top layers.

# let's visualize layer names and layer indices to see how many layers
# we should freeze:
# for i, layer in enumerate(base_model.layers):
#    print(i, layer.name)

# we chose to train the top 2 inception blocks, i.e. we will freeze
# the first 249 layers and unfreeze the rest:
for layer in inception_model.layers[:249]:
   layer.trainable = False
for layer in inception_model.layers[249:]:
   layer.trainable = True

# we need to recompile the model for these modifications to take effect
inception_model_train = Training_routine(inception_model, 10, train_ds, val_ds)
inception_model_test = Testing_routine(inception_model, test_ds)

inception_model_train.training()
inception_model_test.testing()

# Transfer Learning ResNet50



input_tensor = Input(shape=(256, 256, 3))

# create the base pre-trained model
base_model = ResNet50V2(input_tensor = input_tensor, weights='imagenet', include_top=False)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(512, activation='relu')(x)
x = Dropout(0.4)(x)
# and a logistic layer -- let's say we have 2 classes
predictions = Dense(1, activation='sigmoid')(x)

# this is the model we will train
resnet50_model = Model(inputs=base_model.input, outputs=predictions)

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional ResNet50 layers
for layer in base_model.layers:
    layer.trainable = False

resnet50_model_train = Training_routine(resnet50_model, 5, train_ds, val_ds)
resnet50_model_test = Testing_routine(resnet50_model, test_ds)
resnet50_model_train.training()
resnet50_model_test.testing()

for i, layer in enumerate(base_model.layers):
   print(i, layer.name)

# Fine tuning ResNet50
# ---------------- dont know why but fine tuning is not helping here
# at this point, the top layers are well trained and we can start fine-tuning
# convolutional layers from resnet50 V2. We will freeze the bottom N layers
# and train the remaining top layers.

# let's visualize layer names and layer indices to see how many layers
# we should freeze:
# for i, layer in enumerate(base_model.layers):
#    print(i, layer.name)

# we chose to train the top 2 resnet50 blocks, i.e. we will freeze
# the first 130 layers and unfreeze the rest:
for layer in resnet50_model.layers[:130]:
   layer.trainable = False
for layer in resnet50_model.layers[130:]:
   layer.trainable = True

# we need to recompile the model for these modifications to take effect

resnet50_model_train = Training_routine(resnet50_model, 8, train_ds, val_ds)
resnet50_model_test = Testing_routine(resnet50_model, test_ds)

resnet50_model_train.training()
resnet50_model_test.testing()

resnet50_model.summary()

# Grad Cam
img_size = (256, 256)
preprocess_input = keras.applications.resnet_v2.preprocess_input
decode_predictions = keras.applications.resnet_v2.decode_predictions

last_conv_layer_name = "conv5_block3_3_conv"

# The local path to our target image
img_paths = ['/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train/IDRiD_001.jpg',
            '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train/IDRiD_020.jpg',
            '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train/IDRiD_071.jpg',
            '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train/IDRiD_103.jpg',
            '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train/IDRiD_041.jpg',
            '/content/drive/MyDrive/IDRID_dataset/images/clahe_processed/train/IDRiD_256.jpg',
            ]

# display(Image(img_path))


def get_img_array(img_path, size):
    # `img` is a PIL image of size 299x299
    img = keras.preprocessing.image.load_img(img_path, target_size=size)
    # `array` is a float32 Numpy array of shape (299, 299, 3)
    array = keras.preprocessing.image.img_to_array(img)
    # We add a dimension to transform our array into a "batch"
    # of size (1, 299, 299, 3)
    array = np.expand_dims(array, axis=0)
    return array


def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # First, we create a model that maps the input image to the activations
    # of the last conv layer as well as the output predictions
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # We multiply each channel in the feature map array
    # by "how important this channel is" with regard to the top predicted class
    # then sum all the channels to obtain the heatmap class activation
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # For visualization purpose, we will also normalize the heatmap between 0 & 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def save_and_display_gradcam(img_path, heatmap, cam_path="cam.jpg", alpha=0.4):
    # Load the original image
    img = keras.preprocessing.image.load_img(img_path)
    img = keras.preprocessing.image.img_to_array(img)

    # Rescale heatmap to a range 0-255
    heatmap = np.uint8(255 * heatmap)

    # Use jet colormap to colorize heatmap
    jet = cm.get_cmap("jet")

    # Use RGB values of the colormap
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]

    # Create an image with RGB colorized heatmap
    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)
    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)

    # Superimpose the heatmap on original image
    superimposed_img = jet_heatmap * alpha + img
    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)

    # Save the superimposed image
    superimposed_img.save(cam_path)

    # Display Grad CAM
    # display(Image(cam_path))
    return cam_path

# Make model
model = resnet50_model

# Remove last layer's softmax
model.layers[-1].activation = None

  
fig, axes = plt.subplots(nrows=6, ncols=3, figsize = (20,15) )
plt.tight_layout()

i = 0
# Prepare image
for image in img_paths:

  img_array = preprocess_input(get_img_array(image, size=img_size))

  # Generate class activation heatmap
  heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)
  cam_path = save_and_display_gradcam(image, heatmap)

  # original
  img = keras.preprocessing.image.load_img(image)
  axes[i,0].imshow(img)
  if i == 0:
    axes[i,0].set_title('ORIGINAL PICTURE')

  # grad cam
  img = plt.imread(cam_path)
  axes[i,1].imshow(img)
  if i == 0:
    axes[i,1].set_title('GRAD-CAM CLASS ACTIVATION\n')

  # grad cam
  axes[i,2].matshow(heatmap)
  if i == 0:
    axes[i,2].set_title('HEAT MAP GRAD-CAM CLASS ACTIVATION\n')
  i += 1

baseline_model.save = ('baseline_model.h5')
inception_model.save = ('inception_model.h5')
resnet50_model.save = ('resnet50_model.h5')


